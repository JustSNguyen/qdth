{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai \"unstructured==0.13.7\" pypandoc langchain-core langchain-community scikit-learn rank-bm25 faiss-cpu langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_community.document_loaders import UnstructuredRTFLoader\n",
    "import os \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] /Users/kelley/qdth/Unrelated/.DS_Store is not UTF-8 encoded: falling back to latin1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"Unrelated\"\n",
    "\n",
    "unrelated_langchain_docs = []\n",
    "unrelated_labels = []\n",
    "unrelated_example_labels = []\n",
    "# Loop through each document and load it into a langchain document \n",
    "for filename in os.listdir(folder_path):\n",
    "    loader = UnstructuredRTFLoader(os.path.join(folder_path, filename))\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        unrelated_langchain_docs.append(docs[0])\n",
    "        unrelated_labels.append(\"Not Relevant\")\n",
    "        unrelated_example_labels.append(\"Does not contain example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrelated_langchain_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"Related-withExample\"\n",
    "\n",
    "related_with_example_langchain_docs = []\n",
    "related_with_example_labels = []\n",
    "related_with_example_examples = []\n",
    "# Loop through each document and load it into a langchain document \n",
    "for filename in os.listdir(folder_path):\n",
    "    loader = UnstructuredRTFLoader(os.path.join(folder_path, filename))\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        print(docs[0])\n",
    "        related_with_example_langchain_docs.append(docs[0])\n",
    "        related_with_example_labels.append(\"Relevant\")\n",
    "        related_with_example_examples.append(\"Contains example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"Related-withoutExample\"\n",
    "\n",
    "related_no_example_langchain_docs = []\n",
    "related_no_example_labels = []\n",
    "related_no_example_examples = []\n",
    "# Loop through each document and load it into a langchain document \n",
    "for filename in os.listdir(folder_path):\n",
    "    loader = UnstructuredRTFLoader(os.path.join(folder_path, filename))\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        related_no_example_langchain_docs.append(docs[0])\n",
    "        related_no_example_labels.append(\"Relevant\")\n",
    "        related_no_example_examples.append(\"Does not contain example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_docs = unrelated_langchain_docs + related_with_example_langchain_docs + related_no_example_langchain_docs\n",
    "related_labels_truth = unrelated_labels + related_with_example_labels + related_no_example_labels\n",
    "example_labels_truth = unrelated_example_labels + related_with_example_examples + related_no_example_examples\n",
    "print(langchain_docs)\n",
    "print(related_labels_truth)\n",
    "print(example_labels_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings for Retrieval Augmented Generation (RAG) Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "# Classifying the documents \n",
    "vector_store = FAISS.from_documents(langchain_docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured outputs - https://python.langchain.com/v0.1/docs/modules/model_io/chat/structured_output/\n",
    "\n",
    "LLMs really like structure and tend to be more accurate when you \"program\" them, so know we can get back a class with variables that we can use later without parsing the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class ClassificationResponse(BaseModel):\n",
    "    \"\"\"Class to parse the output of the LLM\"\"\"\n",
    "    relevant_or_not: str = Field(description=\"\"\"Answer with ‘Relevant’ if it is about this topic or ‘Not Relevant’ if it is not.\"\"\") #  but does not meet all three conditions, answer ‘Unclear’.\n",
    "    example_or_not: str = Field(description=\"Answer with ‘Contains example’ if it meets all three criteria or ‘Does not contain example’ if it does not.   \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(doc: Document, chunk_size: int = 200, chunk_overlap: int = 40) -> List[Document]:\n",
    "    \"\"\"Take in a document, split it into chunks of a specified size and overlap.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_chain(doc: Document, llm: ChatOpenAI, embeddings: OpenAIEmbeddings, chat_prompt:ChatPromptTemplate) -> ClassificationResponse:\n",
    "    \"\"\"Take in a document, use a language model, embeddings, and chat prompt and return a retrieval based classification response.\n",
    "    Accepts:\n",
    "        doc (Document): The langchain document to classify. Contains the text content to be analyzed.\n",
    "        llm (ChatOpenAI): The language model to use for classification. Configured for structured output.\n",
    "        chat_prompt (ChatPromptTemplate): The chat prompt template to use for generating the classification question.\n",
    "        embeddings (OpenAIEmbeddings): The embeddings to use for the vector store.\n",
    "    Returns:\n",
    "        Response: A Structured Response class defined with pydantic, containing:\n",
    "            - true_or_false (str): \"True\" if the document relates to pharmacy refusals, \"False\" otherwise.\n",
    "            - additional_information (str): Any extra context or details about the classification.\n",
    "\n",
    "    Description:\n",
    "    This function takes a document, uses semantic search and keyword search to classify the document, and returns a structured response.\n",
    "    \"\"\"\n",
    "    chunks = split_into_chunks(doc)\n",
    "    vector_store = FAISS.from_documents(chunks, embeddings) # for semantic search (Vector Search)\n",
    "    vector_store.k = 5\n",
    "    vector_retriever = vector_store.as_retriever()\n",
    "    chatting_chain = RunnableSequence({\"question\": RunnablePassthrough(), \"source\": vector_retriever} | chat_prompt | llm)\n",
    "    response = chatting_chain.invoke(f\"\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(doc: Document, llm: ChatOpenAI, chat_prompt:ChatPromptTemplate) -> ClassificationResponse:\n",
    "    \"\"\"Take in a document, use a language model and chat prompt and return a structured response.\n",
    "    Accepts:\n",
    "        doc (Document): The langchain document to classify. Contains the text content to be analyzed.\n",
    "        llm (ChatOpenAI): The language model to use for classification. Configured for structured output.\n",
    "        chat_prompt (ChatPromptTemplate): The chat prompt template to use for generating the classification question.\n",
    "\n",
    "    Returns:\n",
    "        Response: A Structured Response class defined with pydantic, containing:\n",
    "            - true_or_false (str): \"True\" if the document relates to pharmacy refusals, \"False\" otherwise.\n",
    "            - additional_information (str): Any extra context or details about the classification.\n",
    "\n",
    "    Description:\n",
    "    This function takes a document, uses a specified language model and chat prompt to analyze\n",
    "    the document's content, and determines whether it's related to pharmacy refusals.\n",
    "    The result is returned in a structured format for easy parsing and further processing.\n",
    "    \"\"\"\n",
    "    chatting_chain = RunnableSequence({\"question\": RunnablePassthrough(), \"source\": lambda x: doc.page_content} | chat_prompt | llm)\n",
    "    response = chatting_chain.invoke(\"\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant_or_not='Not Relevant' example_or_not='Does not contain example'\n"
     ]
    }
   ],
   "source": [
    "classify_chat_prompt = ChatPromptTemplate.from_template(template=\"\"\"\n",
    "We are searching for specific examples of pharmaceutical refusals, or the refusal to fulfill a prescription medication at a pharmacy by a pharmacist based on religious or moral objections. Our current corpus contains news articles or legal cases.\n",
    "Read the each of  the attached documents and determine the following:\n",
    "Determine if the article is about pharmaceutical refusals. Answer with ‘Relevant’ if it is about this topic or ‘Not Relevant’ if it is not.\n",
    "For the articles marked as ‘Relevant’, determine whether the article talks about a specific example of a pharmaceutical refusal. To qualify as a specific example of a pharmaceutical refusal, the news article or legal case must have all three conditions:\n",
    "1. Involve a specific person who was refused a prescription at a pharmacy (name not necessary).\n",
    "2. Mention the drug or type of drug that was refused (e.g. emergency contraception, birth control, abortion medication, hormones, HIV medication, etc.).\n",
    "3. State that the refusal was based on moral or religious grounds. It can also relate to an alternative conscientious objection.  \n",
    "    Answer based on the following document:{source} Do not include any other information in your answer.\n",
    "    {question}\"\"\")\n",
    "openai_model = ChatOpenAI(model = \"gpt-4o\")\n",
    "classify_structured_llm = openai_model.with_structured_output(ClassificationResponse)\n",
    "response = run_rag_chain(langchain_docs[0], classify_structured_llm, embeddings, classify_chat_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_predicted = []\n",
    "example_predicted = []\n",
    "document_names = []\n",
    "for i, doc in enumerate(langchain_docs):\n",
    "    print(len(doc.page_content))\n",
    "    response = run_model(doc, classify_structured_llm, classify_chat_prompt)\n",
    "    relevant_predicted.append(response.relevant_or_not)\n",
    "    example_predicted.append(response.example_or_not)\n",
    "    document_names.append(doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_df = pd.DataFrame({\"document_name\": document_names, \"Predicted Relevance\": relevant_predicted, \"Actual Relevance\": related_labels_truth, \"Predicted Example\": example_predicted, \"Actual Example\": example_labels_truth})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.18%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(related_labels_truth, relevant_predicted)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.91%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(example_labels_truth, example_predicted)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_df.to_csv(\"Train_Test_classification_gpt4o_relevant_and_example1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the information from the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractionResponse(BaseModel):\n",
    "    \"\"\"Class to parse the output of the LLM\"\"\"\n",
    "    date: str = Field(description=\"The date when the incident occurred. Only list the date if it refers to when a specific pharmacist refused a prescription, not legal case timelines or rulings, or the date the article was published or uploaded. Answer with None if not mentioned.\")\n",
    "    location: str = Field(description=\"The state, city, or county where a specific pharmacist refused a prescription. Answer with None if not mentioned.\")\n",
    "    pharmacy_name: str = Field(description=\"The pharmacy that originally refused the medication. Answer with None if not mentioned.\")\n",
    "    drug_or_classification: str = Field(description=\"The drug, item, or broad drug category that was refused. Answer with None if not mentioned.\")\n",
    "    patient_name: str = Field(description=\"The name of the patient who was refused medication. Answer with None if not mentioned.\")\n",
    "    patient_demographics: str = Field(description=\"The demographics of the patient (e.g. Age, Race, Gender, Sexuality, etc.). Answer with None if not mentioned.\")\n",
    "    refusal_reason: str = Field(description=\"The reason the pharmacist refused to provide the desired medication. Answer with None if not mentioned.\")\n",
    "    patient_outcome: str = Field(description=\"The outcome for the patient. Did they eventually receive the drug? If yes, indicate if it was the same pharmacy or a different one. Answer with None if not mentioned.\")\n",
    "    pharmacist_outcome: str = Field(description=\"The outcome for the pharmacist. Was legal action brought against the pharmacist or pharmacy, and if so, what was the result? Answer with None if not mentioned.\")\n",
    "    news_source: str = Field(description=\"Where the story was reported (name of newspaper, publication, headline, and date published). Answer with None if not mentioned.\")\n",
    "    additional_information: str = Field(description=\"Any important additional information about the refusal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_structured_llm = openai_model.with_structured_output(ExtractionResponse)\n",
    "extraction_chat_prompt = ChatPromptTemplate.from_template(template=\"\"\"Answer the following questions based on the following document:{source}. From the document, which clarifies specific instances of pharmaceutical refusals based upon moral or religious grounds, extract the following information. If the information is not available, return ‘None’\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_responses = []\n",
    "date = []\n",
    "location = []\n",
    "pharmacy_name = []\n",
    "drug_or_classification = []\n",
    "patient_name = []\n",
    "patient_demographics = []\n",
    "refusal_reason = []\n",
    "patient_outcome = []\n",
    "pharmacist_outcome = []\n",
    "news_source = []\n",
    "additional_information = []\n",
    "for i, doc in enumerate(langchain_docs):\n",
    "    bool = example_predicted[i]\n",
    "    if bool == \"Contains example\":\n",
    "        response = run_model(doc, extraction_structured_llm, extraction_chat_prompt)\n",
    "        date.append(response.date)\n",
    "        location.append(response.location)\n",
    "        pharmacy_name.append(response.pharmacy_name)\n",
    "        drug_or_classification.append(response.drug_or_classification)\n",
    "        patient_name.append(response.patient_name)\n",
    "        patient_demographics.append(response.patient_demographics)\n",
    "        refusal_reason.append(response.refusal_reason)\n",
    "        patient_outcome.append(response.patient_outcome)\n",
    "        pharmacist_outcome.append(response.pharmacist_outcome)\n",
    "        news_source.append(response.news_source)\n",
    "        additional_information.append(response.additional_information)\n",
    "    else:\n",
    "        date.append(\"None\")\n",
    "        location.append(\"None\")\n",
    "        pharmacy_name.append(\"None\")\n",
    "        drug_or_classification.append(\"None\")\n",
    "        patient_name.append(\"None\")\n",
    "        patient_demographics.append(\"None\")\n",
    "        refusal_reason.append(\"None\")\n",
    "        patient_outcome.append(\"None\")\n",
    "        pharmacist_outcome.append(\"None\")\n",
    "        news_source.append(\"None\")\n",
    "        additional_information.append(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns from the earlier DataFrame\n",
    "extraction_df = pd.concat([classify_df, pd.DataFrame({\n",
    "    \"date\": date,\n",
    "    \"location\": location,\n",
    "    \"pharmacy_name\": pharmacy_name,\n",
    "    \"drug_or_classification\": drug_or_classification,\n",
    "    \"patient_name\": patient_name,\n",
    "    \"patient_demographics\": patient_demographics,\n",
    "    \"refusal_reason\": refusal_reason,\n",
    "    \"patient_outcome\": patient_outcome,\n",
    "    \"pharmacist_outcome\": pharmacist_outcome,\n",
    "    \"news_source\": news_source,\n",
    "    \"additional_information\": additional_information\n",
    "})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_df.to_csv(\"TT_classification_and_extraction_gpt4o_prompt2_relevant_and_example.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
