{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai \"unstructured==0.13.7\" pypandoc langchain-core langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_community.document_loaders import UnstructuredRTFLoader\n",
    "import os \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"15\"\n",
    "\n",
    "langchain_docs = []\n",
    "# Loop through each document and load it into a langchain document \n",
    "for filename in os.listdir(folder_path):\n",
    "    loader = UnstructuredRTFLoader(os.path.join(folder_path, filename))\n",
    "    docs = loader.load()\n",
    "    print(docs)\n",
    "    langchain_docs.append(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured outputs - https://python.langchain.com/v0.1/docs/modules/model_io/chat/structured_output/\n",
    "\n",
    "LLMs really like structure and tend to be more accurate when you \"program\" them, so know we can get back a class with variables that we can use later without parsing the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Class to parse the output of the LLM\"\"\"\n",
    "    true_or_false: str = Field(description=\"\"\"Answer with ‘True’ if it is about this topic or ‘False’ if it is not.If it is about pharmaceutical refusals, but does not meet all three conditions, answer ‘Unclear’.\"\"\")\n",
    "    additional_information: str = Field(description=\"Any additional information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_doc(doc: Document, llm: ChatOpenAI, chat_prompt:ChatPromptTemplate) -> Response:\n",
    "    \"\"\"Classify a document as true or false related to pharmacy refusals.\n",
    "    Accepts:\n",
    "        doc (Document): The langchain document to classify. Contains the text content to be analyzed.\n",
    "        llm (ChatOpenAI): The language model to use for classification. Configured for structured output.\n",
    "        chat_prompt (ChatPromptTemplate): The chat prompt template to use for generating the classification question.\n",
    "\n",
    "    Returns:\n",
    "        Response: A Structured Response class defined with pydantic, containing:\n",
    "            - true_or_false (str): \"True\" if the document relates to pharmacy refusals, \"False\" otherwise.\n",
    "            - additional_information (str): Any extra context or details about the classification.\n",
    "\n",
    "    Description:\n",
    "    This function takes a document, uses a specified language model and chat prompt to analyze\n",
    "    the document's content, and determines whether it's related to pharmacy refusals.\n",
    "    The result is returned in a structured format for easy parsing and further processing.\n",
    "    \"\"\"\n",
    "    chatting_chain = RunnableSequence({\"question\": RunnablePassthrough(), \"source\": lambda x: doc.page_content} | chat_prompt | llm)\n",
    "    response = chatting_chain.invoke(\" \")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_template(template=\"\"\"\n",
    "    We are searching for specific examples of pharmaceutical refusals, or the refusal to fulfill a prescription medication at a pharmacy by a pharmacist based on religious or moral objections. Our current corpus contains news articles or legal cases.\n",
    "    To qualify as a specific example of a pharmaceutical refusal, the news article or legal case must have all three conditions:\n",
    "    1. Involve a specific person who was refused a prescription at a pharmacy (name not necessary).\n",
    "    2. Mention the drug or type of drug that was refused (e.g. emergency contraception, birth control, abortion medication, hormones, HIV medication, etc.).\n",
    "    3. State that the refusal was based on moral or religious grounds. It can also relate to an alternative conscientious objection.\n",
    "    Based on these conditions, read each of the attached documents and determine if it mentions specific instances of prescriptions being refused on moral or religious grounds.              \n",
    "    {source} \n",
    "    {question}\"\"\")\n",
    "openai_model = ChatOpenAI(model = \"gpt-4o\")\n",
    "structured_llm = openai_model.with_structured_output(Response)\n",
    "response = classify_doc(langchain_docs[0], structured_llm, chat_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_or_false = []\n",
    "additional_information = []\n",
    "document_names = []\n",
    "for doc in langchain_docs:\n",
    "    response = classify_doc(doc, structured_llm, chat_prompt)\n",
    "    true_or_false.append(response.true_or_false)\n",
    "    additional_information.append(response.additional_information)\n",
    "    document_names.append(doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"document_name\": document_names, \"Pharmacy Refusal true_or_false\": true_or_false, \"additional_information\": additional_information})\n",
    "df.to_csv(\"15_classifications_promptteam1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
