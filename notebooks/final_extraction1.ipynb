{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (0.2.3)\n",
      "Requirement already satisfied: unstructured==0.13.7 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (0.13.7)\n",
      "Requirement already satisfied: pypandoc in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (1.14)\n",
      "Requirement already satisfied: langchain-core in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (0.3.12)\n",
      "Requirement already satisfied: langchain-community in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (0.3.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: faiss-cpu in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (1.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (0.3.0)\n",
      "Requirement already satisfied: ipykernel in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (6.29.5)\n",
      "Requirement already satisfied: pandas in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: chardet in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (5.2.0)\n",
      "Requirement already satisfied: filetype in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (0.4.27)\n",
      "Requirement already satisfied: lxml in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (5.3.0)\n",
      "Requirement already satisfied: nltk in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (3.9.1)\n",
      "Requirement already satisfied: tabulate in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (0.9.0)\n",
      "Requirement already satisfied: requests in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (4.12.3)\n",
      "Requirement already satisfied: emoji in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (2.14.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (2024.4.27)\n",
      "Requirement already satisfied: langdetect in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (1.0.9)\n",
      "Requirement already satisfied: numpy in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (3.10.0)\n",
      "Requirement already satisfied: backoff in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (0.26.1)\n",
      "Requirement already satisfied: wrapt in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured==0.13.7) (1.16.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.52.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-openai) (1.52.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-core) (0.1.136)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-core) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-core) (9.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-community) (3.10.10)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-community) (0.3.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langchain-community) (2.6.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: appnope in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (1.8.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (8.28.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: psutil in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.15.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from dataclasses-json->unstructured==0.13.7) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from dataclasses-json->unstructured==0.13.7) (0.9.0)\n",
      "Requirement already satisfied: decorator in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.6)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (3.10.9)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from requests->unstructured==0.13.7) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from requests->unstructured==0.13.7) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from requests->unstructured==0.13.7) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from requests->unstructured==0.13.7) (2024.8.30)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from beautifulsoup4->unstructured==0.13.7) (2.6)\n",
      "Requirement already satisfied: click in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from nltk->unstructured==0.13.7) (8.1.7)\n",
      "Requirement already satisfied: cryptography>=3.1 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured-client->unstructured==0.13.7) (43.0.3)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured-client->unstructured==0.13.7) (0.2.0)\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured-client->unstructured==0.13.7) (1.0.6)\n",
      "Requirement already satisfied: pypdf>=4.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from unstructured-client->unstructured==0.13.7) (5.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from cryptography>=3.1->unstructured-client->unstructured==0.13.7) (1.17.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured==0.13.7) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Requirement already satisfied: pycparser in /Users/kelley/qdth/datathon/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured==0.13.7) (2.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai \"unstructured==0.13.7\" pypandoc langchain-core langchain-community scikit-learn faiss-cpu langchain-text-splitters ipykernel pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelley/qdth/datathon/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_community.document_loaders import UnstructuredRTFLoader, TextLoader\n",
    "import os \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Documents (for making sure the model is working positive cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_langchain_docs = []\n",
    "test_document_type = []\n",
    "folder_path = \"/Users/kelley/qdth/TrainTestData/Relevant_Positive\"\n",
    "for filename in os.listdir(folder_path): # Finds every file in the folder\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path) # Loads a txt file (RTF Loader is always works )\n",
    "    docs = loader.load()\n",
    "    test_langchain_docs.append(docs[0])\n",
    "    test_document_type.append(filename.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magazine articles \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_type = []\n",
    "magazine_langchain_docs = []\n",
    "\n",
    "folder_path = \"/Users/kelley/qdth/FullData/Magazines_Journals2014-Present1-500byRelevence_cleaned\"\n",
    "\n",
    "# Loop through each document and load it into a langchain document \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        magazine_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Magazine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/kelley/qdth/FullData/Magazines_Journals2014-Present501-808byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        magazine_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Magazine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newpaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper_langchain_docs = []\n",
    "folder_path = \"/Users/kelley/qdth/FullData/Magazines_Journals2014-Present1-500byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        newspaper_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Newspaper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/kelley/qdth/FullData/Newspapers2014-Present501-1000byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        newspaper_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Newspaper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_transcript_langchain_docs = []\n",
    "folder_path = \"/Users/kelley/qdth/FullData/NewsTranscripts2014-Present1-500byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        news_transcript_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"News Transcript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/kelley/qdth/FullData/NewsTranscripts2014-Present501-1000byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        news_transcript_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"News Transcript\")\n",
    "# Related with example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newswires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newswire_langchain_docs = []\n",
    "folder_path = \"/Users/kelley/qdth/FullData/Newswires_Press_Releases2014-Present1-500byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        newswire_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Newswire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/kelley/qdth/FullData/Newswires_Press_Releases2014-Present501-1000byRelevence_cleaned-1\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        newswire_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Newswire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_langchain_docs = []\n",
    "folder_path = \"/Users/kelley/qdth/FullData/Web_based_2014-Present1-500byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        web_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Web Based\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3828\n",
      "3828\n"
     ]
    }
   ],
   "source": [
    "langchain_docs = magazine_langchain_docs + newspaper_langchain_docs + news_transcript_langchain_docs + newswire_langchain_docs + web_langchain_docs\n",
    "print(len(langchain_docs))\n",
    "print(len(document_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_langchain_docs = langchain_docs[:400]\n",
    "filtered_document_type = document_type[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings for Retrieval Augmented Generation (RAG) Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured outputs - https://python.langchain.com/v0.1/docs/modules/model_io/chat/structured_output/\n",
    "\n",
    "LLMs really like structure and tend to be more accurate when you \"program\" them, so know we can get back a class with variables that we can use later without parsing the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationResponse(BaseModel):\n",
    "    \"\"\"Class to parse the output of the LLM\"\"\"\n",
    "    about_pharmaceutical_refusals: str = Field(description=\"\"\"Answer with ‘True’ if it is about this topic or ‘False’ if it is not.If it is about pharmaceutical refusals, but does not meet all three conditions, answer ‘Unclear’.\"\"\") #  but does not meet all three conditions, answer ‘Unclear’.\n",
    "    additional_information: str = Field(description=\"Any extra context or details about the classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rag Chain for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(doc: Document, chunk_size: int = 200, chunk_overlap: int = 40) -> List[Document]:\n",
    "    \"\"\"Take in a document, split it into chunks of a specified size and overlap.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_chain(doc: Document, llm: ChatOpenAI, embeddings: OpenAIEmbeddings, chat_prompt:ChatPromptTemplate) -> ClassificationResponse:\n",
    "    \"\"\"Take in a document, use a language model, embeddings, and chat prompt and return a retrieval based classification response.\n",
    "    Accepts:\n",
    "        doc (Document): The langchain document to classify. Contains the text content to be analyzed.\n",
    "        llm (ChatOpenAI): The language model to use for classification. Configured for structured output.\n",
    "        chat_prompt (ChatPromptTemplate): The chat prompt template to use for generating the classification question.\n",
    "        embeddings (OpenAIEmbeddings): The embeddings to use for the vector store.\n",
    "    Returns:\n",
    "        Response: A Structured Response class defined with pydantic, containing:\n",
    "            - true_or_false (str): \"True\" if the document relates to pharmacy refusals, \"False\" otherwise.\n",
    "            - additional_information (str): Any extra context or details about the classification.\n",
    "\n",
    "    Description:\n",
    "    This function takes a document, uses semantic search and keyword search to classify the document, and returns a structured response.\n",
    "    \"\"\"\n",
    "    print(doc.page_content)\n",
    "    chunks = split_into_chunks(doc)\n",
    "    vector_store = FAISS.from_documents(chunks, embeddings) # for semantic search (Vector Search)\n",
    "    vector_store.k = 10\n",
    "    vector_retriever = vector_store.as_retriever()\n",
    "    rag_chain = RunnableSequence({\"question\": RunnablePassthrough(), \"source\": vector_retriever} | chat_prompt | llm)\n",
    "    response = rag_chain.invoke(f\"\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular LLM for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_structured_llm(doc: Document, llm: ChatOpenAI, chat_prompt:ChatPromptTemplate) -> ClassificationResponse:\n",
    "    \"\"\"Take in a document, use a language model and chat prompt and return a structured response.\n",
    "    Accepts:\n",
    "        doc (Document): The langchain document to classify. Contains the text content to be analyzed.\n",
    "        llm (ChatOpenAI): The language model to use for classification. Configured for structured output.\n",
    "        chat_prompt (ChatPromptTemplate): The chat prompt template to use for generating the classification question.\n",
    "\n",
    "    Returns:\n",
    "        Response: A Structured Response class defined with pydantic, containing:\n",
    "            - true_or_false (str): \"True\" if the document relates to pharmacy refusals, \"False\" otherwise.\n",
    "            - additional_information (str): Any extra context or details about the classification.\n",
    "\n",
    "    Description:\n",
    "    This function takes a document, uses a specified language model and chat prompt to analyze\n",
    "    the document's content, and determines whether it's related to pharmacy refusals.\n",
    "    The result is returned in a structured format for easy parsing and further processing.\n",
    "    \"\"\"\n",
    "    chatting_chain = RunnableSequence({\"question\": RunnablePassthrough(), \"source\": lambda x: doc.page_content} | chat_prompt | llm)\n",
    "    response = chatting_chain.invoke(\"\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model for a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about_pharmaceutical_refusals='True' additional_information=\"The document describes a specific case where a pharmacist in Michigan refused to dispense misoprostol, a medication intended to expedite the miscarriage process, to a woman named Rachel Peterson. The refusal was based on the pharmacist's religious beliefs as he identified himself as a 'good Catholic male' who could not 'in good conscience' fill the prescription. This instance meets all three conditions for pharmaceutical refusal: it involved a specific person, mentioned the drug misoprostol, and was based on religious grounds.\"\n"
     ]
    }
   ],
   "source": [
    "classify_chat_prompt = ChatPromptTemplate.from_template(template=\"\"\"\n",
    "    We are searching for specific examples of pharmaceutical refusals, or the refusal to fulfill a prescription medication at a pharmacy by a pharmacist based on religious or moral objections. Our current corpus contains news articles or legal cases.\n",
    "    To qualify as a specific example of a pharmaceutical refusal, the news article or legal case must have all three conditions:\n",
    "    1. Involve a specific person who was refused a prescription at a pharmacy (name not necessary).\n",
    "    2. Mention the drug or type of drug that was refused (e.g. emergency contraception, birth control, abortion medication, hormones, HIV medication, etc.).\n",
    "    3. State that the refusal was based on moral or religious grounds. It can also relate to an alternative conscientious objection.\n",
    "    Based on these conditions, read each of the attached documents and determine if it mentions specific instances of prescriptions being refused on moral or religious grounds.    \n",
    "    Answer based on the following document:{source} Do not include any other information in your answer.\n",
    "    {question}\"\"\")\n",
    "openai_model = ChatOpenAI(model = \"gpt-4o\", api_key= os.getenv(\"OPENAI_API_KEY\"))\n",
    "classify_structured_llm = openai_model.with_structured_output(ClassificationResponse)\n",
    "response = run_structured_llm(test_langchain_docs[0], classify_structured_llm, classify_chat_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44155\n",
      "32268\n",
      "29092\n"
     ]
    }
   ],
   "source": [
    "predicted_pharmaceutical_refusals = []\n",
    "document_names = []\n",
    "for i, doc in enumerate(filtered_langchain_docs):\n",
    "    print(len(doc.page_content))\n",
    "    response = run_structured_llm(doc, classify_structured_llm, classify_chat_prompt)\n",
    "    predicted_pharmaceutical_refusals.append(response.about_pharmaceutical_refusals)\n",
    "    document_names.append(f'{doc.metadata[\"source\"].split(\"/\")[-2]}/{doc.metadata[\"source\"].split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>document_type</th>\n",
       "      <th>Pharmaceutical Refusal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Relevant_Positive/Michigan Pharmacist Refused ...</td>\n",
       "      <td>Michigan Pharmacist Refused to Dispense Miscar...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Relevant_Positive/Morning-after pill denied; s...</td>\n",
       "      <td>Morning-after pill denied; suit follows</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Relevant_Positive/San Diego woman says CVS pha...</td>\n",
       "      <td>San Diego woman says CVS pharmacist refused to...</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       document_name  \\\n",
       "0  Relevant_Positive/Michigan Pharmacist Refused ...   \n",
       "1  Relevant_Positive/Morning-after pill denied; s...   \n",
       "2  Relevant_Positive/San Diego woman says CVS pha...   \n",
       "\n",
       "                                       document_type Pharmaceutical Refusal  \n",
       "0  Michigan Pharmacist Refused to Dispense Miscar...                   True  \n",
       "1            Morning-after pill denied; suit follows                   True  \n",
       "2  San Diego woman says CVS pharmacist refused to...                Unclear  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_df = pd.DataFrame({\"document_name\": document_names, \"document_type\": filtered_document_type, \"Pharmaceutical Refusal\": predicted_pharmaceutical_refusals})\n",
    "classify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the information from the documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output Blueprint  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractionResponse(BaseModel):\n",
    "    \"\"\"Class to parse the output of the LLM\"\"\"\n",
    "    date: str = Field(description=\"The date when the incident occurred. Only list the date if it refers to when a specific pharmacist refused a prescription, not legal case timelines or rulings, or the date the article was published or uploaded. Answer with None if not mentioned.\")\n",
    "    location: str = Field(description=\"The state, city, or county where a specific pharmacist refused a prescription. Answer with None if not mentioned.\")\n",
    "    pharmacy_name: str = Field(description=\"The pharmacy that originally refused the medication. Answer with None if not mentioned.\")\n",
    "    drug_or_classification: str = Field(description=\"The drug, item, or broad drug category that was refused. Answer with None if not mentioned.\")\n",
    "    patient_name: str = Field(description=\"The name of the patient who was refused medication. Answer with None if not mentioned.\")\n",
    "    patient_demographics: str = Field(description=\"The demographics of the patient (e.g. Age, Race, Gender, Sexuality, etc.). Answer with None if not mentioned.\")\n",
    "    refusal_reason: str = Field(description=\"The reason the pharmacist refused to provide the desired medication. Answer with None if not mentioned.\")\n",
    "    patient_outcome: str = Field(description=\"The outcome for the patient. Did they eventually receive the drug? If yes, indicate if it was the same pharmacy or a different one. Answer with None if not mentioned.\")\n",
    "    pharmacist_outcome: str = Field(description=\"The outcome for the pharmacist. Was legal action brought against the pharmacist or pharmacy, and if so, what was the result? Answer with None if not mentioned.\")\n",
    "    news_source: str = Field(description=\"Where the story was reported (name of newspaper, publication, headline, and date published). Answer with None if not mentioned.\")\n",
    "    additional_information: str = Field(description=\"Any important additional information about the refusal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_structured_llm = openai_model.with_structured_output(ExtractionResponse)\n",
    "extraction_chat_prompt = ChatPromptTemplate.from_template(template=\"\"\"Answer the following questions based on the following document:{source}. From the document, which clarifies specific instances of pharmaceutical refusals based upon moral or religious grounds, extract the following information. If the information is not available, return ‘None’\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the extraction process for all pharmaceutical refusals documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_responses = []\n",
    "date = []\n",
    "location = []\n",
    "pharmacy_name = []\n",
    "drug_or_classification = []\n",
    "patient_name = []\n",
    "patient_demographics = []\n",
    "refusal_reason = []\n",
    "patient_outcome = []\n",
    "pharmacist_outcome = []\n",
    "news_source = []\n",
    "additional_information = []\n",
    "for i, doc in enumerate(filtered_langchain_docs):\n",
    "    bool = predicted_pharmaceutical_refusals[i]\n",
    "    if bool == \"True\":\n",
    "        response = run_structured_llm(doc, extraction_structured_llm, extraction_chat_prompt)\n",
    "        date.append(response.date)\n",
    "        location.append(response.location)\n",
    "        pharmacy_name.append(response.pharmacy_name)\n",
    "        drug_or_classification.append(response.drug_or_classification)\n",
    "        patient_name.append(response.patient_name)\n",
    "        patient_demographics.append(response.patient_demographics)\n",
    "        refusal_reason.append(response.refusal_reason)\n",
    "        patient_outcome.append(response.patient_outcome)\n",
    "        pharmacist_outcome.append(response.pharmacist_outcome)\n",
    "        news_source.append(response.news_source)\n",
    "        additional_information.append(response.additional_information)\n",
    "    else:\n",
    "        date.append(\"None\")\n",
    "        location.append(\"None\")\n",
    "        pharmacy_name.append(\"None\")\n",
    "        drug_or_classification.append(\"None\")\n",
    "        patient_name.append(\"None\")\n",
    "        patient_demographics.append(\"None\")\n",
    "        refusal_reason.append(\"None\")\n",
    "        patient_outcome.append(\"None\")\n",
    "        pharmacist_outcome.append(\"None\")\n",
    "        news_source.append(\"None\")\n",
    "        additional_information.append(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving info to a dataframe and exporting it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_df = pd.DataFrame({\n",
    "    \"date\": date,\n",
    "    \"location\": location,\n",
    "    \"pharmacy_name\": pharmacy_name,\n",
    "    \"drug_or_classification\": drug_or_classification,\n",
    "    \"patient_name\": patient_name,\n",
    "    \"patient_demographics\": patient_demographics,\n",
    "    \"refusal_reason\": refusal_reason,\n",
    "    \"patient_outcome\": patient_outcome,\n",
    "    \"pharmacist_outcome\": pharmacist_outcome,\n",
    "    \"news_source\": news_source,\n",
    "    \"additional_information\": additional_information\n",
    "})\n",
    "# Add new columns from the earlier DataFrame\n",
    "final_df = pd.concat([classify_df, extraction_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"Classification_and_Extraction_Final_400_Documents.csv\", index=False)\n",
    "## Filtering for only the pharmaceutical refusals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>document_type</th>\n",
       "      <th>Pharmaceutical Refusal</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>pharmacy_name</th>\n",
       "      <th>drug_or_classification</th>\n",
       "      <th>patient_name</th>\n",
       "      <th>patient_demographics</th>\n",
       "      <th>refusal_reason</th>\n",
       "      <th>patient_outcome</th>\n",
       "      <th>pharmacist_outcome</th>\n",
       "      <th>news_source</th>\n",
       "      <th>additional_information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Relevant_Positive/Michigan Pharmacist Refused ...</td>\n",
       "      <td>Michigan Pharmacist Refused to Dispense Miscar...</td>\n",
       "      <td>True</td>\n",
       "      <td>July 1, 2018</td>\n",
       "      <td>Petoskey, Michigan</td>\n",
       "      <td>Meijer</td>\n",
       "      <td>misoprostol</td>\n",
       "      <td>Rachel Peterson</td>\n",
       "      <td>35, Female, Ionia, Michigan resident</td>\n",
       "      <td>Pharmacist's religious beliefs as a good Catho...</td>\n",
       "      <td>Received medication from Meijer pharmacy in ho...</td>\n",
       "      <td>Pharmacist no longer employed by Meijer as of ...</td>\n",
       "      <td>The New York Times, October 18, 2018</td>\n",
       "      <td>The pharmacist refused to transfer the prescri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Relevant_Positive/Morning-after pill denied; s...</td>\n",
       "      <td>Morning-after pill denied; suit follows</td>\n",
       "      <td>True</td>\n",
       "      <td>January 2019</td>\n",
       "      <td>McGregor, Minnesota</td>\n",
       "      <td>Thrifty White</td>\n",
       "      <td>Ella (emergency contraceptive)</td>\n",
       "      <td>Andrea Anderson</td>\n",
       "      <td>Mother of five</td>\n",
       "      <td>Religious beliefs of the pharmacist, believing...</td>\n",
       "      <td>Andrea Anderson eventually got her prescriptio...</td>\n",
       "      <td>Andrea Anderson sued under the Minnesota Human...</td>\n",
       "      <td>Star Tribune (Minneapolis, MN), August 1, 2022...</td>\n",
       "      <td>The case may be the first in the nation brough...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       document_name  \\\n",
       "0  Relevant_Positive/Michigan Pharmacist Refused ...   \n",
       "1  Relevant_Positive/Morning-after pill denied; s...   \n",
       "\n",
       "                                       document_type Pharmaceutical Refusal  \\\n",
       "0  Michigan Pharmacist Refused to Dispense Miscar...                   True   \n",
       "1            Morning-after pill denied; suit follows                   True   \n",
       "\n",
       "           date             location  pharmacy_name  \\\n",
       "0  July 1, 2018   Petoskey, Michigan         Meijer   \n",
       "1  January 2019  McGregor, Minnesota  Thrifty White   \n",
       "\n",
       "           drug_or_classification     patient_name  \\\n",
       "0                     misoprostol  Rachel Peterson   \n",
       "1  Ella (emergency contraceptive)  Andrea Anderson   \n",
       "\n",
       "                   patient_demographics  \\\n",
       "0  35, Female, Ionia, Michigan resident   \n",
       "1                        Mother of five   \n",
       "\n",
       "                                      refusal_reason  \\\n",
       "0  Pharmacist's religious beliefs as a good Catho...   \n",
       "1  Religious beliefs of the pharmacist, believing...   \n",
       "\n",
       "                                     patient_outcome  \\\n",
       "0  Received medication from Meijer pharmacy in ho...   \n",
       "1  Andrea Anderson eventually got her prescriptio...   \n",
       "\n",
       "                                  pharmacist_outcome  \\\n",
       "0  Pharmacist no longer employed by Meijer as of ...   \n",
       "1  Andrea Anderson sued under the Minnesota Human...   \n",
       "\n",
       "                                         news_source  \\\n",
       "0               The New York Times, October 18, 2018   \n",
       "1  Star Tribune (Minneapolis, MN), August 1, 2022...   \n",
       "\n",
       "                              additional_information  \n",
       "0  The pharmacist refused to transfer the prescri...  \n",
       "1  The case may be the first in the nation brough...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['Pharmaceutical Refusal'] == \"True\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
