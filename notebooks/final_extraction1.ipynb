{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai \"unstructured==0.13.7\" pypandoc langchain-core langchain-community scikit-learn faiss-cpu langchain-text-splitters ipykernel pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-ollama ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import chardet\n",
    "import csv\n",
    "\n",
    "from typing import List\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_community.document_loaders import UnstructuredRTFLoader, TextLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Ollama model (current ollama version is 0.5.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful classes and methods definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataRowInfo:\n",
    "    \"\"\"\"Parses individual rows from the manual label CSV file\"\"\"\n",
    "    def __init__(self, about_pharmacy_refusals, additional_info=\"\"):\n",
    "        self.about_pharmacy_refusals = about_pharmacy_refusals\n",
    "        self.additional_info = additional_info \n",
    "\n",
    "    def not_labeled(self):\n",
    "        return self.about_pharmacy_refusals == \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationResponse(BaseModel):\n",
    "    \"\"\"Class to parse the output of the LLM\"\"\"\n",
    "    about_pharmaceutical_refusals: str = Field(description=\"\"\"Answer with Yes’ if it is about this topic or No’ if it is not.If it is about pharmaceutical refusals, but does not meet all three conditions, answer ‘Unclear’.\"\"\") #  but does not meet all three conditions, answer ‘Unclear’.\n",
    "    additional_information: str = Field(description=\"Any extra context or details about the classification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_structured_llm(doc: Document, llm: ChatOpenAI, chat_prompt:ChatPromptTemplate) -> ClassificationResponse:\n",
    "    \"\"\"Take in a document, use a language model and chat prompt and return a structured response.\n",
    "    Accepts:\n",
    "        doc (Document): The langchain document to classify. Contains the text content to be analyzed.\n",
    "        llm (ChatOpenAI): The language model to use for classification. Configured for structured output.\n",
    "        chat_prompt (ChatPromptTemplate): The chat prompt template to use for generating the classification question.\n",
    "\n",
    "    Returns:\n",
    "        Response: A Structured Response class defined with pydantic, containing:\n",
    "            - true_or_false (str): \"Yes\" if the document relates to pharmacy refusals, \"No\" otherwise.\n",
    "            - additional_information (str): Any extra context or details about the classification.\n",
    "\n",
    "    Description:\n",
    "    This function takes a document, uses a specified language model and chat prompt to analyze\n",
    "    the document's content, and determines whether it's related to pharmacy refusals.\n",
    "    The result is returned in a structured format for easy parsing and further processing.\n",
    "    \"\"\"\n",
    "    chatting_chain = RunnableSequence({\"question\": RunnablePassthrough(), \"source\": lambda x: doc.page_content} | chat_prompt | llm)\n",
    "    response = chatting_chain.invoke(\"\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_chat_prompt = ChatPromptTemplate.from_template(template=\"\"\"\n",
    "    We are searching for specific examples of pharmaceutical refusals, or the refusal to fulfill a prescription medication at a pharmacy by a pharmacist based on religious or moral objections. Our current corpus contains news articles or legal cases.\n",
    "    To qualify as a specific example of a pharmaceutical refusal, the news article or legal case must have all three conditions:\n",
    "    1. Involve a specific person who was refused a prescription at a pharmacy (name not necessary).\n",
    "    2. Mention the drug or type of drug that was refused (e.g. emergency contraception, birth control, abortion medication, hormones, HIV medication, etc.).\n",
    "    3. State that the refusal was based on moral or religious grounds. It can also relate to an alternative conscientious objection.\n",
    "    Based on these conditions, read each of the attached documents and determine if it mentions specific instances of prescriptions being refused on moral or religious grounds.    \n",
    "    Answer based on the following document:{source} Do not include any other information in your answer.\n",
    "    {question}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ollama model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = ChatOllama(model=\"llama3.2\").with_structured_output(ClassificationResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from manual label CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_manual_label_csv_file_path = \"../TestData/QSIDE Pharmacy Refusal Data Label - Web_based_2014-Present1-500byRelevence_cleaned.csv\"\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "    \n",
    "full_manual_label_csv_file_path = os.path.join(current_directory, relative_manual_label_csv_file_path)\n",
    "\n",
    "manual_label_data_by_name = dict()\n",
    "\n",
    "with open(full_manual_label_csv_file_path, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile)\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        document_name = row['Document name'].strip()\n",
    "        \n",
    "        about_pharmacy_refusals = row.get('about_pharmacy_refusals', '').strip()\n",
    "        additional_notes = row.get('Additional notes', '').strip()\n",
    "        \n",
    "        test_data_row_info = TestDataRowInfo(\n",
    "            about_pharmacy_refusals=about_pharmacy_refusals, \n",
    "            additional_info=additional_notes\n",
    "        )\n",
    "        \n",
    "        manual_label_data_by_name[document_name] = test_data_row_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_label_for_file(file_path, llm_model):\n",
    "    loader = TextLoader(file_path, encoding='utf-8')\n",
    "    docs = loader.load()\n",
    "    response = run_structured_llm(docs[0], llm_model, classify_chat_prompt)\n",
    "\n",
    "    if not response:\n",
    "        return None \n",
    "\n",
    "    return response.about_pharmaceutical_refusals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"../FullData/Web_based_2014-Present1-500byRelevence_cleaned\"]\n",
    "\n",
    "result_csv_file_name = \"validation_result.csv\"\n",
    "\n",
    "with open(result_csv_file_name, 'w', newline='', encoding='utf-8') as result_csv_file:\n",
    "    result_csv_file_writer = csv.writer(result_csv_file)\n",
    "    \n",
    "    result_csv_file_writer.writerow(['document_name', 'actual_label', 'model_predicted_label'])\n",
    "\n",
    "    for folder_path in folder_paths:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            filename_without_extension = os.path.splitext(filename)[0].strip()\n",
    "        \n",
    "            # Some file names contain a strange leading apostrophe ('), which for some reasons is omitted when copy to CSV file so this is a \"hack\" to handle those documents \n",
    "            if filename_without_extension[0] == \"'\":\n",
    "                filename_without_extension = filename_without_extension[1:].strip()\n",
    "\n",
    "            actual_data = manual_label_data_by_name[filename_without_extension]\n",
    "            if actual_data.not_labeled():\n",
    "                continue \n",
    "\n",
    "            actual_label = actual_data.about_pharmacy_refusals\n",
    "            try:\n",
    "                model_predicted_label = get_predicted_label_for_file(file_path, ollama_model)\n",
    "                result_csv_file_writer.writerow([filename_without_extension, actual_label, model_predicted_label])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Documents (for making sure the model is working positive cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_langchain_docs = []\n",
    "test_document_type = []\n",
    "folder_path = \"/Users/kelley/qdth/TrainTestData/Relevant_Positive\"\n",
    "for filename in os.listdir(folder_path): # Finds every file in the folder\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path) # Loads a txt file (RTF Loader is always works )\n",
    "    docs = loader.load()\n",
    "    test_langchain_docs.append(docs[0])\n",
    "    test_document_type.append(filename.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magazine articles \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_type = []\n",
    "magazine_langchain_docs = []\n",
    "\n",
    "folder_path = \"/Users/kelley/qdth/FullData/Magazines_Journals2014-Present1-500byRelevence_cleaned\"\n",
    "\n",
    "# Loop through each document and load it into a langchain document \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        magazine_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Magazine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/kelley/qdth/FullData/Magazines_Journals2014-Present501-808byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        magazine_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Magazine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newpaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper_langchain_docs = []\n",
    "folder_path = \"/Users/kelley/qdth/FullData/Magazines_Journals2014-Present1-500byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        newspaper_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Newspaper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/kelley/qdth/FullData/Newspapers2014-Present501-1000byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        newspaper_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Newspaper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_transcript_langchain_docs = []\n",
    "folder_path = \"/Users/kelley/qdth/FullData/NewsTranscripts2014-Present1-500byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        news_transcript_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"News Transcript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/kelley/qdth/FullData/NewsTranscripts2014-Present501-1000byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        news_transcript_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"News Transcript\")\n",
    "# Related with example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newswires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newswire_langchain_docs = []\n",
    "folder_path = \"/Users/kelley/qdth/FullData/Newswires_Press_Releases2014-Present1-500byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        newswire_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Newswire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/kelley/qdth/FullData/Newswires_Press_Releases2014-Present501-1000byRelevence_cleaned-1\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        newswire_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Newswire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_langchain_docs = []\n",
    "folder_path = \"/Users/kelley/qdth/FullData/Web_based_2014-Present1-500byRelevence_cleaned\"\n",
    "# Loop through each document and load it into a langchain document  \n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    loader = TextLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    if len(docs[0].page_content) > 0:\n",
    "        web_langchain_docs.append(docs[0])\n",
    "        document_type.append(\"Web Based\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3828\n",
      "3828\n"
     ]
    }
   ],
   "source": [
    "langchain_docs = magazine_langchain_docs + newspaper_langchain_docs + news_transcript_langchain_docs + newswire_langchain_docs + web_langchain_docs\n",
    "print(len(langchain_docs))\n",
    "print(len(document_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_langchain_docs = langchain_docs[:400]\n",
    "filtered_document_type = document_type[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings for Retrieval Augmented Generation (RAG) Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured outputs - https://python.langchain.com/v0.1/docs/modules/model_io/chat/structured_output/\n",
    "\n",
    "LLMs really like structure and tend to be more accurate when you \"program\" them, so know we can get back a class with variables that we can use later without parsing the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rag Chain for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(doc: Document, chunk_size: int = 200, chunk_overlap: int = 40) -> List[Document]:\n",
    "    \"\"\"Take in a document, split it into chunks of a specified size and overlap.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_chain(doc: Document, llm: ChatOpenAI, embeddings: OpenAIEmbeddings, chat_prompt:ChatPromptTemplate) -> ClassificationResponse:\n",
    "    \"\"\"Take in a document, use a language model, embeddings, and chat prompt and return a retrieval based classification response.\n",
    "    Accepts:\n",
    "        doc (Document): The langchain document to classify. Contains the text content to be analyzed.\n",
    "        llm (ChatOpenAI): The language model to use for classification. Configured for structured output.\n",
    "        chat_prompt (ChatPromptTemplate): The chat prompt template to use for generating the classification question.\n",
    "        embeddings (OpenAIEmbeddings): The embeddings to use for the vector store.\n",
    "    Returns:\n",
    "        Response: A Structured Response class defined with pydantic, containing:\n",
    "            - true_or_false (str): \"True\" if the document relates to pharmacy refusals, \"False\" otherwise.\n",
    "            - additional_information (str): Any extra context or details about the classification.\n",
    "\n",
    "    Description:\n",
    "    This function takes a document, uses semantic search and keyword search to classify the document, and returns a structured response.\n",
    "    \"\"\"\n",
    "    print(doc.page_content)\n",
    "    chunks = split_into_chunks(doc)\n",
    "    vector_store = FAISS.from_documents(chunks, embeddings) # for semantic search (Vector Search)\n",
    "    vector_store.k = 10\n",
    "    vector_retriever = vector_store.as_retriever()\n",
    "    rag_chain = RunnableSequence({\"question\": RunnablePassthrough(), \"source\": vector_retriever} | chat_prompt | llm)\n",
    "    response = rag_chain.invoke(f\"\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model for a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = ChatOpenAI(model = \"gpt-4o\", api_key= os.getenv(\"OPENAI_API_KEY\"))\n",
    "classify_structured_llm = openai_model.with_structured_output(ClassificationResponse)\n",
    "response = run_structured_llm(test_langchain_docs[0], classify_structured_llm, classify_chat_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44155\n",
      "32268\n",
      "29092\n"
     ]
    }
   ],
   "source": [
    "predicted_pharmaceutical_refusals = []\n",
    "document_names = []\n",
    "for i, doc in enumerate(filtered_langchain_docs):\n",
    "    print(len(doc.page_content))\n",
    "    response = run_structured_llm(doc, classify_structured_llm, classify_chat_prompt)\n",
    "    predicted_pharmaceutical_refusals.append(response.about_pharmaceutical_refusals)\n",
    "    document_names.append(f'{doc.metadata[\"source\"].split(\"/\")[-2]}/{doc.metadata[\"source\"].split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>document_type</th>\n",
       "      <th>Pharmaceutical Refusal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Relevant_Positive/Michigan Pharmacist Refused ...</td>\n",
       "      <td>Michigan Pharmacist Refused to Dispense Miscar...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Relevant_Positive/Morning-after pill denied; s...</td>\n",
       "      <td>Morning-after pill denied; suit follows</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Relevant_Positive/San Diego woman says CVS pha...</td>\n",
       "      <td>San Diego woman says CVS pharmacist refused to...</td>\n",
       "      <td>Unclear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       document_name  \\\n",
       "0  Relevant_Positive/Michigan Pharmacist Refused ...   \n",
       "1  Relevant_Positive/Morning-after pill denied; s...   \n",
       "2  Relevant_Positive/San Diego woman says CVS pha...   \n",
       "\n",
       "                                       document_type Pharmaceutical Refusal  \n",
       "0  Michigan Pharmacist Refused to Dispense Miscar...                   True  \n",
       "1            Morning-after pill denied; suit follows                   True  \n",
       "2  San Diego woman says CVS pharmacist refused to...                Unclear  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_df = pd.DataFrame({\"document_name\": document_names, \"document_type\": filtered_document_type, \"Pharmaceutical Refusal\": predicted_pharmaceutical_refusals})\n",
    "classify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the information from the documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output Blueprint  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractionResponse(BaseModel):\n",
    "    \"\"\"Class to parse the output of the LLM\"\"\"\n",
    "    date: str = Field(description=\"The date when the incident occurred. Only list the date if it refers to when a specific pharmacist refused a prescription, not legal case timelines or rulings, or the date the article was published or uploaded. Answer with None if not mentioned.\")\n",
    "    location: str = Field(description=\"The state, city, or county where a specific pharmacist refused a prescription. Answer with None if not mentioned.\")\n",
    "    pharmacy_name: str = Field(description=\"The pharmacy that originally refused the medication. Answer with None if not mentioned.\")\n",
    "    drug_or_classification: str = Field(description=\"The drug, item, or broad drug category that was refused. Answer with None if not mentioned.\")\n",
    "    patient_name: str = Field(description=\"The name of the patient who was refused medication. Answer with None if not mentioned.\")\n",
    "    patient_demographics: str = Field(description=\"The demographics of the patient (e.g. Age, Race, Gender, Sexuality, etc.). Answer with None if not mentioned.\")\n",
    "    refusal_reason: str = Field(description=\"The reason the pharmacist refused to provide the desired medication. Answer with None if not mentioned.\")\n",
    "    patient_outcome: str = Field(description=\"The outcome for the patient. Did they eventually receive the drug? If yes, indicate if it was the same pharmacy or a different one. Answer with None if not mentioned.\")\n",
    "    pharmacist_outcome: str = Field(description=\"The outcome for the pharmacist. Was legal action brought against the pharmacist or pharmacy, and if so, what was the result? Answer with None if not mentioned.\")\n",
    "    news_source: str = Field(description=\"Where the story was reported (name of newspaper, publication, headline, and date published). Answer with None if not mentioned.\")\n",
    "    additional_information: str = Field(description=\"Any important additional information about the refusal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_structured_llm = openai_model.with_structured_output(ExtractionResponse)\n",
    "extraction_chat_prompt = ChatPromptTemplate.from_template(template=\"\"\"Answer the following questions based on the following document:{source}. From the document, which clarifies specific instances of pharmaceutical refusals based upon moral or religious grounds, extract the following information. If the information is not available, return ‘None’\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the extraction process for all pharmaceutical refusals documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_responses = []\n",
    "date = []\n",
    "location = []\n",
    "pharmacy_name = []\n",
    "drug_or_classification = []\n",
    "patient_name = []\n",
    "patient_demographics = []\n",
    "refusal_reason = []\n",
    "patient_outcome = []\n",
    "pharmacist_outcome = []\n",
    "news_source = []\n",
    "additional_information = []\n",
    "for i, doc in enumerate(filtered_langchain_docs):\n",
    "    bool = predicted_pharmaceutical_refusals[i]\n",
    "    if bool == \"True\":\n",
    "        response = run_structured_llm(doc, extraction_structured_llm, extraction_chat_prompt)\n",
    "        date.append(response.date)\n",
    "        location.append(response.location)\n",
    "        pharmacy_name.append(response.pharmacy_name)\n",
    "        drug_or_classification.append(response.drug_or_classification)\n",
    "        patient_name.append(response.patient_name)\n",
    "        patient_demographics.append(response.patient_demographics)\n",
    "        refusal_reason.append(response.refusal_reason)\n",
    "        patient_outcome.append(response.patient_outcome)\n",
    "        pharmacist_outcome.append(response.pharmacist_outcome)\n",
    "        news_source.append(response.news_source)\n",
    "        additional_information.append(response.additional_information)\n",
    "    else:\n",
    "        date.append(\"None\")\n",
    "        location.append(\"None\")\n",
    "        pharmacy_name.append(\"None\")\n",
    "        drug_or_classification.append(\"None\")\n",
    "        patient_name.append(\"None\")\n",
    "        patient_demographics.append(\"None\")\n",
    "        refusal_reason.append(\"None\")\n",
    "        patient_outcome.append(\"None\")\n",
    "        pharmacist_outcome.append(\"None\")\n",
    "        news_source.append(\"None\")\n",
    "        additional_information.append(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving info to a dataframe and exporting it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_df = pd.DataFrame({\n",
    "    \"date\": date,\n",
    "    \"location\": location,\n",
    "    \"pharmacy_name\": pharmacy_name,\n",
    "    \"drug_or_classification\": drug_or_classification,\n",
    "    \"patient_name\": patient_name,\n",
    "    \"patient_demographics\": patient_demographics,\n",
    "    \"refusal_reason\": refusal_reason,\n",
    "    \"patient_outcome\": patient_outcome,\n",
    "    \"pharmacist_outcome\": pharmacist_outcome,\n",
    "    \"news_source\": news_source,\n",
    "    \"additional_information\": additional_information\n",
    "})\n",
    "# Add new columns from the earlier DataFrame\n",
    "final_df = pd.concat([classify_df, extraction_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"Classification_and_Extraction_Final_400_Documents.csv\", index=False)\n",
    "## Filtering for only the pharmaceutical refusals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df['Pharmaceutical Refusal'] == \"True\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
